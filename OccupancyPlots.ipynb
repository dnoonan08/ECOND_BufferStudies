{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of number of link that are assigned\n",
    "linkSummary = pd.read_csv('geomInfo/ModuleLinkSummary.csv')\n",
    "linkSummary = linkSummary[(linkSummary.Cassette==0) & (linkSummary.Layer>=5) & (linkSummary.Layer<=9)]\n",
    "linkSummary.set_index(['Layer','ModU','ModV'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from csv files.  This is used to extract average data sizes\n",
    "\n",
    "daq_Data = pd.concat([pd.read_csv(f'Data/ttbar_DAQ_data_{i}.csv') for i in range(16)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of wedges, and assign x and y positions for drawing maps\n",
    "wedges = daq_Data.groupby(['layer','waferu','waferv']).any()[['HDM']].reset_index()\n",
    "\n",
    "wedges['y'] = wedges.waferv\n",
    "wedges['x'] = 0\n",
    "wedges.loc[:,'x'] = (2+wedges.y-2*wedges.waferu)\n",
    "wedges.y *= 1.5\n",
    "wedges.x *= -3**.5/2\n",
    "wedges.set_index(['layer','waferu','waferv'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to look through output logs of condor jobs to extract and accumulate the results across several runs\n",
    "# if you just ran interactivel, need to just get the info on the overflows, max size, etc into a dataframe.\n",
    "\n",
    "def getDF(inputDF, LogName=None,Nstart=0,N=100):\n",
    "    fullData = inputDF.groupby(['layer','waferu','waferv']).mean()\n",
    "    fullData['eTx_assigned'] = linkSummary.ECOND_eTX\n",
    "    fullData.eTx_assigned = fullData.eTx_assigned.fillna(1).astype(int)\n",
    "\n",
    "    fullData['eTx_30percent'] = np.ceil((fullData.TotalWords/53.3333)*1.3).astype(int)\n",
    "    fullData['eTx_Mean'] = np.ceil((fullData.TotalWords/53.3333))\n",
    "    \n",
    "    if not LogName is None:\n",
    "        data_overflow = []\n",
    "        data_maxSize = []\n",
    "        L1As_issued=0\n",
    "        fileName = f'LogFiles/{LogName}_{Nstart}.stdout'\n",
    "        with open(fileName,'r') as _file:\n",
    "            for line in _file:\n",
    "                if 'overflows= ' in line:\n",
    "                    data_overflow.append(eval(line[10:]))\n",
    "                if 'maxSize= ' in line:\n",
    "                    data_maxSize.append(eval(line[8:]))\n",
    "                if 'L1As issued' in line:\n",
    "                    L1As_issued += int(line.split()[0])\n",
    "                    \n",
    "        data_overflow=np.array(data_overflow)\n",
    "        data_maxSize=np.array(data_maxSize)\n",
    "\n",
    "        for i_file in range(Nstart+1,Nstart+N):\n",
    "            fileName = f'LogFiles/{LogName}_{i_file}.stdout'\n",
    "            with open(fileName,'r') as _file:\n",
    "                for line in _file:\n",
    "                    if 'eTx' in line:\n",
    "                        i = int(line.split()[0])-1\n",
    "                    if 'overflows= ' in line:\n",
    "                        overflow=np.array(eval(line[10:]))\n",
    "                        overflow[overflow<0] = 99999999\n",
    "                        data_overflow[i] += overflow\n",
    "                    if 'maxSize= ' in line:\n",
    "                        maxSize=np.array(eval(line[8:]))\n",
    "                        data_maxSize[i] = np.maximum(data_maxSize[i], maxSize)\n",
    "                    if 'L1As issued' in line:\n",
    "                        L1As_issued += int(line.split()[0])\n",
    "                        \n",
    "        x = ((data_overflow.transpose()==0)*np.arange(1,7))\n",
    "        x[x==0]=99\n",
    "        minLinks = x.min(axis=1)\n",
    "        fullData['min_eTx'] = minLinks\n",
    "\n",
    "        nLinks = minLinks\n",
    "        maxSize = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize'] = maxSize    \n",
    "\n",
    "        \n",
    "        nLinks = fullData.eTx_assigned.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "            overflows.append(data_overflow.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize_assigned'] = maxSize\n",
    "        fullData['overflows_assigned'] = overflows\n",
    "\n",
    "\n",
    "        nLinks = fullData.eTx_30percent.values\n",
    "        maxSize = []\n",
    "        overflows = []\n",
    "        for i in range(len(nLinks)):\n",
    "            maxSize.append(data_maxSize.transpose()[i][nLinks[i]-1])\n",
    "            overflows.append(data_overflow.transpose()[i][nLinks[i]-1])\n",
    "        fullData['maxSize_30percent'] = maxSize\n",
    "        fullData['overflows_30percent'] = overflows\n",
    "    return fullData, L1As_issued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData,L1As = getDF(daq_Data,LogName='DAQBufferStudy_69415084',Nstart=0,N=100)\n",
    "print(L1As)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionaly of the labels for different types of plots\n",
    "Labels ={'occ':{'Title':'Average L1A Occupancy, Layer %i',\n",
    "                'colorLabel':'Avg. Occ. Above Zero Suppression',\n",
    "                'nDec':1,\n",
    "                'zMax':260},\n",
    "         'TotalWords':{'Title':'Average L1A Size (32b Words), Layer %i',\n",
    "                      'colorLabel':'Avg. L1A Size (32b words)',\n",
    "                      'nDec':1,\n",
    "                      'zMax':200},\n",
    "         'EmptyLinks':{'Title':'Average Number of Empty eRx Packets, Layer %i',\n",
    "                      'colorLabel':'Avg. # of Empty eRx Packets',\n",
    "                      'nDec':1,\n",
    "                      'zMax':6},\n",
    "         'eTx_assigned':{'Title':'Number of eTx assigned, Layer %i',\n",
    "                      'colorLabel':'# of eTx',\n",
    "                      'nDec':0,\n",
    "                      'zMax':6},\n",
    "         'eTx_30percent':{'Title':'Number of eTx assuming 30 percent overhead, Layer %i',\n",
    "                      'colorLabel':'# of eTx',\n",
    "                      'nDec':0,\n",
    "                      'zMax':6},\n",
    "         'eTx_Mean':{'Title':'Number of eTx based on mean data, no rounding, Layer %i',\n",
    "                      'colorLabel':'# of eTx',\n",
    "                      'nDec':2,\n",
    "                      'zMax':6},\n",
    "         'min_eTx':{'Title':'Min number of eTx with 0 overflows, Layer %i',\n",
    "                      'colorLabel':'# of eTx',\n",
    "                      'nDec':0,\n",
    "                      'zMax':6},\n",
    "         'maxSize':{'Title':'Max buffer size, with 0 overflows, Layer %i',\n",
    "                      'colorLabel':'Buffer size (32b words)',\n",
    "                      'nDec':0,\n",
    "                      'zMax':1600},\n",
    "         'maxSize_assigned':{'Title':'Max buffer size, using assigned number of links, Layer %i',\n",
    "                      'colorLabel':'Buffer size (32b words)',\n",
    "                      'nDec':0,\n",
    "                      'zMax':1600},\n",
    "         'overflows_assigned':{'Title':'Overflow counter, using assigned number of links, Layer %i',\n",
    "                      'colorLabel':'# of buffer overflows',\n",
    "                      'nDec':0,\n",
    "                      'zMax':40000},\n",
    "         'maxSize_30percent':{'Title':'Max buffer size, using link assignment from 30 percent overhead, Layer %i',\n",
    "                      'colorLabel':'Buffer size (32b words)',\n",
    "                      'nDec':0,\n",
    "                      'zMax':1600},\n",
    "         'overflows_30percent':{'Title':'Overflow counter, using link assignment from 30 percent overhead, Layer %i',\n",
    "                      'colorLabel':'# of buffer overflows',\n",
    "                      'nDec':0,\n",
    "                      'zMax':40000},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePlot(var,patches,df=fullData,extra=\"\"):\n",
    "    data = df.loc[layer,var].values.flatten()\n",
    "\n",
    "    waferCollection = PatchCollection(patches,cmap=matplotlib.cm.coolwarm)\n",
    "    waferCollection.set_array(data)\n",
    "    waferCollection.set_clim([0,Labels[var]['zMax']])\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    ax.add_collection(waferCollection)\n",
    "    plt.axis([0,16,-1,15])\n",
    "    # ax.set_xticklabels([])\n",
    "    # ax.set_yticklabels([]);\n",
    "    cbar = plt.colorbar(waferCollection)\n",
    "    cbar.set_label(Labels[var]['colorLabel'],fontsize=14)\n",
    "\n",
    "    wedge['data'] = data\n",
    "\n",
    "    plt.title(Labels[var]['Title']%layer,fontsize=24)\n",
    "    for x,y,d in wedge[['x','y','data']].values:\n",
    "    #     s = data[i]\n",
    "        plt.text(x,y,f'%.{Labels[var][\"nDec\"]}f'%d,fontsize=14,horizontalalignment='center',verticalalignment='center')\n",
    "\n",
    "                 \n",
    "\n",
    "    fig.savefig(f'Plots/{var}_layer{layer}{extra}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in [5,7,9]:\n",
    "    wedge = wedges.loc[layer]\n",
    "    patches = []\n",
    "\n",
    "    for w in wedge.index:\n",
    "        patches.append(mpatches.RegularPolygon((wedge.loc[w].x,wedge.loc[w].y),6,.95))\n",
    "    for k in Labels:\n",
    "        print(k)\n",
    "        makePlot(k,df=fullData,extra=\"_OldTTbarTests\",patches=patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgcalPythonEnv",
   "language": "python",
   "name": "hgcalpythonenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
